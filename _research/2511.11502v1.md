---
abstract: Large vision-language models (LVLMs) are powerful, yet they remain unreliable
  due to object hallucinations. In this work, we show that in many hallucinatory predictions
  the LVLM effectively ignores the image and instead relies on previously generated
  output (prelim) tokens to infer new objects. We quantify this behavior via the mutual
  information between the image and the predicted object conditioned on the prelim,
  demonstrating that weak image dependence strongly correlates with hallucination.
  Building on this finding, we introduce the Prelim Attention Score (PAS), a lightweight,
  training-free signal computed from attention weights over prelim tokens. PAS requires
  no additional forward passes and can be computed on the fly during inference. Exploiting
  this previously overlooked signal, PAS achieves state-of-the-art object-hallucination
  detection across multiple models and datasets, enabling real-time filtering and
  intervention.
authors:
- Nhat Hoang-Xuan
- Minh Vu
- My T. Thai
- Manish Bhattarai
layout: research_post
pdf: https://arxiv.org/pdf/2511.11502v1
title: 'PAS : Prelim Attention Score for Detecting Object Hallucinations in Large
  Vision--Language Models'
year: 2025
---
Large vision-language models (LVLMs) are powerful, yet they remain unreliable due to object hallucinations. In this work, we show that in many hallucinatory predictions the LVLM effectively ignores the image and instead relies on previously generated output (prelim) tokens to infer new objects. We quantify this behavior via the mutual information between the image and the predicted object conditioned on the prelim, demonstrating that weak image dependence strongly correlates with hallucination. Building on this finding, we introduce the Prelim Attention Score (PAS), a lightweight, training-free signal computed from attention weights over prelim tokens. PAS requires no additional forward passes and can be computed on the fly during inference. Exploiting this previously overlooked signal, PAS achieves state-of-the-art object-hallucination detection across multiple models and datasets, enabling real-time filtering and intervention.
