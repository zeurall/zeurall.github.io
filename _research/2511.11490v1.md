---
abstract: In this work, we estimate the intrinsic dimension (iD) of the Radio Galaxy
  Zoo (RGZ) dataset using a score-based diffusion model. We examine how the iD estimates
  vary as a function of Bayesian neural network (BNN) energy scores, which measure
  how similar the radio sources are to the MiraBest subset of the RGZ dataset. We
  find that out-of-distribution sources exhibit higher iD values, and that the overall
  iD for RGZ exceeds those typically reported for natural image datasets. Furthermore,
  we analyse how iD varies across Fanaroff-Riley (FR) morphological classes and as
  a function of the signal-to-noise ratio (SNR). While no relationship is found between
  FR I and FR II classes, a weak trend toward higher SNR at lower iD. Future work
  using the RGZ dataset could make use of the relationship between iD and energy scores
  to quantitatively study and improve the representations learned by various self-supervised
  learning algorithms.
authors:
- Joan Font-Quer Roset
- Devina Mohan
- Anna Scaife
layout: research_post
pdf: https://arxiv.org/pdf/2511.11490v1
title: Intrinsic Dimension Estimation for Radio Galaxy Zoo using Diffusion Models
year: 2025
---
In this work, we estimate the intrinsic dimension (iD) of the Radio Galaxy Zoo (RGZ) dataset using a score-based diffusion model. We examine how the iD estimates vary as a function of Bayesian neural network (BNN) energy scores, which measure how similar the radio sources are to the MiraBest subset of the RGZ dataset. We find that out-of-distribution sources exhibit higher iD values, and that the overall iD for RGZ exceeds those typically reported for natural image datasets. Furthermore, we analyse how iD varies across Fanaroff-Riley (FR) morphological classes and as a function of the signal-to-noise ratio (SNR). While no relationship is found between FR I and FR II classes, a weak trend toward higher SNR at lower iD. Future work using the RGZ dataset could make use of the relationship between iD and energy scores to quantitatively study and improve the representations learned by various self-supervised learning algorithms.
